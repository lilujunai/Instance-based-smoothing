{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Density Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Replace True Labels with Probabilities from KDE + Fitting LR\n",
    "#### y = Score_Positive / (Score_positive + Score_negative)\n",
    "\n",
    "\n",
    "## Method 2: Generate double points from KDE + LR fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR:\n",
    "    def __init__(self, learnRate = 0.001, nIter = 1000, use_intercept = True, smoothed = False):\n",
    "        self.learnRate = learnRate\n",
    "        self.nIter = nIter\n",
    "        self.intercept = use_intercept\n",
    "        self.smooth = smoothed\n",
    "        \n",
    "    def crossEntropy(self, P, Y):\n",
    "        return (-Y * np.log(P) - (1 - Y + 1e-9) * np.log(1 - P + 1e-9)).mean()\n",
    "    \n",
    "    def sigmoid(self, Z):\n",
    "        return 1 / (1 + np.exp(-Z))\n",
    "    \n",
    "    def SGD(self, X_train, y_train, X_test, y_test, y_train_smoothed = np.zeros(1)):\n",
    "        if self.smooth == False:\n",
    "            y_train_smoothed = np.zeros(len(y_train))\n",
    "        #Add Intercept\n",
    "        if self.intercept == True:\n",
    "            X_train = np.concatenate((np.ones((X_train.shape[0], 1)), X_train), axis=1)\n",
    "            X_test = np.concatenate((np.ones((X_test.shape[0], 1)), X_test), axis=1)\n",
    "        #Initialize Weights by zeros\n",
    "        self.Ws = np.zeros(X_train.shape[1])\n",
    "        oldWs = np.zeros(X_train.shape[1])\n",
    "        CETEST = 1\n",
    "        self.converge = self.nIter\n",
    "        #Update weights for n Iterations\n",
    "        for i in range(self.nIter):\n",
    "            if i % 5000 == 0 and i != 0:\n",
    "                print('Finished ', i, ' iterations --> Test CE:', CETEST)\n",
    "            #Shuffle indeces\n",
    "            p = np.random.permutation(len(X_train))\n",
    "            X_train = X_train[p]\n",
    "            y_train = y_train[p]\n",
    "            y_train_smoothed = y_train_smoothed[p]\n",
    "            for row,y_t, y_t_s in zip(X_train, y_train, y_train_smoothed):\n",
    "                Z = np.dot(row, self.Ws)\n",
    "                y_p = self.sigmoid(Z)\n",
    "                if self.smooth:\n",
    "                    gradient = np.dot(row.T, (y_p - y_t_s))\n",
    "                else:\n",
    "                    gradient = np.dot(row.T, (y_p - y_t))\n",
    "                self.Ws -= self.learnRate * gradient\n",
    "            \n",
    "            if i % 50 == 0:\n",
    "                diff = np.absolute(oldWs - self.Ws).sum() / len(self.Ws)\n",
    "                #print(diff, oldWs, self.Ws)\n",
    "                if diff <= 0.001:\n",
    "                    self.converge = i\n",
    "                    break\n",
    "                oldWs = self.Ws\n",
    "    \n",
    "    def predict_prob(self, X):\n",
    "        #Add Intercept\n",
    "        if self.intercept == True:\n",
    "            intercept = np.ones((X.shape[0], 1))\n",
    "            X = np.concatenate((intercept, X), axis=1)\n",
    "        return self.sigmoid(np.dot(X, self.Ws))\n",
    "    \n",
    "    def predict(self, X, threshold = 0.5):\n",
    "        return self.predict_prob(X) >= threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "dataset_names = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk('Datasets\\\\'):\n",
    "    for file in f:\n",
    "        if '.csv' in file:\n",
    "            dataset_names.append(file)\n",
    "            files.append(os.path.join(r, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {'Name':[], 'Instances':[], 'Features':[], 'PosClassRatio':[], \n",
    "        'NTestCE':[], 'M1TestCE':[], 'M2TestCE':[], 'PTestCE':[], 'SKTestCE':[], \n",
    "        'NTrainCE':[], 'M1TrainCE':[], 'M2TrainCE':[], 'PTrainCE':[], 'SKTrainCE':[], \n",
    "        'NTestAcc':[], 'M1TestAcc':[], 'M2TestAcc':[], 'PTestAcc':[], 'SKTestAcc':[],\n",
    "        'NTrainAcc':[], 'M1TrainAcc':[], 'M2TrainAcc':[], 'PTrainAcc':[], 'SKTrainAcc':[],\n",
    "       'NConverge':[], 'M1Converge':[], 'M2Converge':[], 'PConverge':[]\n",
    "      }\n",
    "results = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRate = 0.0001\n",
    "nIter = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_features(data):\n",
    "    n_rows = len(data)\n",
    "    n_feats = len(data.columns) - 1\n",
    "    pos_class_ratio = (data['class'] == 1).sum() / n_rows\n",
    "    return n_rows, n_feats, pos_class_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal LR Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_results(X_train, y_train, X_test, y_test):\n",
    "    model = LR(learnRate = LRate, nIter = nIter)\n",
    "    model.SGD(X_train.values, y_train.values, X_test.values, y_test.values)\n",
    "    \n",
    "    y_pred_test  = model.predict_prob(X_test)\n",
    "    y_pred_train = model.predict_prob(X_train)\n",
    "    \n",
    "    CE_test  = model.crossEntropy(y_pred_test,  y_test)\n",
    "    CE_train = model.crossEntropy(y_pred_train, y_train)\n",
    "    \n",
    "    y_pred_test_labels  = model.predict(X_test)\n",
    "    y_pred_train_labels = model.predict(X_train)\n",
    "    \n",
    "    acc_test  = accuracy_score(y_test,  y_pred_test_labels ) * 100\n",
    "    acc_train = accuracy_score(y_train, y_pred_train_labels) * 100\n",
    "    \n",
    "    return acc_test, CE_test, acc_train, CE_train, model.converge, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Platt Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def platt_results(X_train, y_train, X_test, y_test):\n",
    "    #smoothed Labels\n",
    "    NP = (y_train > 0.5).sum()\n",
    "    NN = len(y_train) - NP\n",
    "    y_train_smoothed = np.zeros(len(y_train))\n",
    "    y_tmp = y_train.values\n",
    "    for i in range(len(y_train)):\n",
    "        if y_tmp[i] > 0:\n",
    "            y_train_smoothed[i] = 1 - 1 / (NP + 2)\n",
    "        else:\n",
    "            y_train_smoothed[i] = 1 / (NN + 2)\n",
    "        \n",
    "    model = LR(learnRate = LRate, nIter = nIter, smoothed = True)\n",
    "    model.SGD(X_train.values, y_train.values, X_test.values, y_test.values, y_train_smoothed)\n",
    "    \n",
    "    y_pred_test  = model.predict_prob(X_test)\n",
    "    y_pred_train = model.predict_prob(X_train)\n",
    "    \n",
    "    CE_test  = model.crossEntropy(y_pred_test,  y_test)\n",
    "    CE_train = model.crossEntropy(y_pred_train, y_train)\n",
    "    \n",
    "    y_pred_test_labels  = model.predict(X_test)\n",
    "    y_pred_train_labels = model.predict(X_train)\n",
    "    \n",
    "    acc_test  = accuracy_score(y_test,  y_pred_test_labels ) * 100\n",
    "    acc_train = accuracy_score(y_train, y_pred_train_labels) * 100\n",
    "    \n",
    "    return acc_test, CE_test, acc_train, CE_train, model.converge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_results(X_train, y_train, X_test, y_test, model):\n",
    "    model_sklearn = LogisticRegression(random_state=24, solver='lbfgs').fit(X_train, y_train)\n",
    "    y_pred_test  = model_sklearn.predict_proba(X_test)\n",
    "    y_pred_train = model_sklearn.predict_proba(X_train)\n",
    "    \n",
    "    CE_test  = model.crossEntropy(y_pred_test[:,1] , y_test)\n",
    "    CE_train = model.crossEntropy(y_pred_train[:,1], y_train)\n",
    "    \n",
    "    y_pred_test_labels  = model_sklearn.predict(X_test)\n",
    "    y_pred_train_labels = model_sklearn.predict(X_train)\n",
    "    \n",
    "    acc_test  = accuracy_score(y_test,  y_pred_test_labels ) * 100\n",
    "    acc_train = accuracy_score(y_train, y_pred_train_labels) * 100\n",
    "    \n",
    "    return acc_test, CE_test, acc_train, CE_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Kernels of positive and negative classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernels(X_train, y_train):\n",
    "    #split training set into positive and negative instances (S1, S0)\n",
    "    poss = []\n",
    "    negs = []\n",
    "    y_tmp = y_train.values\n",
    "    for i in range(len(y_train)):\n",
    "        if y_tmp[i] == 0:\n",
    "            negs.append(i)\n",
    "        else:\n",
    "            poss.append(i)\n",
    "    S0 = (X_train.iloc[negs,:]).T.values\n",
    "    S1 = (X_train.iloc[poss,:]).T.values\n",
    "    #Create positive and negative classes kernels\n",
    "    neg_kernel = stats.gaussian_kde(S0)\n",
    "    pos_kernel = stats.gaussian_kde(S1)\n",
    "    \n",
    "    #Calculate smoothed labels based on values from the kernels\n",
    "    P_S0 = pos_kernel.evaluate(S0) / (pos_kernel.evaluate(S0) + neg_kernel.evaluate(S0))\n",
    "    P_S1 = pos_kernel.evaluate(S1) / (pos_kernel.evaluate(S1) + neg_kernel.evaluate(S1))\n",
    "    y_train_prob = np.zeros(len(y_train))\n",
    "    neg_index = 0\n",
    "    pos_index = 0\n",
    "    for i in range(len(y_train)):\n",
    "        if y_tmp[i] == 0:\n",
    "            y_train_prob[i] = P_S0[neg_index]\n",
    "            neg_index += 1\n",
    "        else:\n",
    "            y_train_prob[i] = P_S1[pos_index]\n",
    "            pos_index += 1\n",
    "            \n",
    "    return pos_kernel, neg_kernel, y_train_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M1_results(X_train, y_train, X_test, y_test, y_train_prob):\n",
    "    #Train the LR model with the smoothed labels\n",
    "    model = LR(learnRate = LRate, nIter = nIter, smoothed = True)\n",
    "    model.SGD(X_train.values, y_train.values, X_test.values, y_test.values, y_train_prob)\n",
    "    \n",
    "    y_pred_test  = model.predict_prob(X_test)\n",
    "    y_pred_train = model.predict_prob(X_train)\n",
    "    \n",
    "    CE_test  = model.crossEntropy(y_pred_test,  y_test)\n",
    "    CE_train = model.crossEntropy(y_pred_train, y_train)\n",
    "    \n",
    "    y_pred_test_labels  = model.predict(X_test)\n",
    "    y_pred_train_labels = model.predict(X_train)\n",
    "    \n",
    "    acc_test  = accuracy_score(y_test,  y_pred_test_labels ) * 100\n",
    "    acc_train = accuracy_score(y_train, y_pred_train_labels) * 100\n",
    "    \n",
    "    return acc_test, CE_test, acc_train, CE_train, model.converge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M2_results(X_train, y_train, X_test, y_test, pos_kernel, neg_kernel):\n",
    "    N0_2 = int((y_train == 0).sum() * 2)\n",
    "    N1_2 = int((y_train == 1).sum() * 2)\n",
    "    neg2 = neg_kernel.resample(N0_2)\n",
    "    pos2 = pos_kernel.resample(N1_2)\n",
    "\n",
    "    X_train2 = np.array(np.concatenate((neg2.T, pos2.T), axis=0) )\n",
    "    y_train2 = np.asarray([0] * N0_2 + [1] * N1_2)\n",
    "    \n",
    "    #Train the LR model with Method2\n",
    "    model = LR(learnRate = LRate, nIter = nIter)\n",
    "    model.SGD(X_train2, y_train2, X_test, y_test)\n",
    "    \n",
    "    y_pred_test  = model.predict_prob(X_test)\n",
    "    y_pred_train = model.predict_prob(X_train)\n",
    "    \n",
    "    CE_test  = model.crossEntropy(y_pred_test,  y_test)\n",
    "    CE_train = model.crossEntropy(y_pred_train, y_train)\n",
    "    \n",
    "    y_pred_test_labels  = model.predict(X_test)\n",
    "    y_pred_train_labels = model.predict(X_train)\n",
    "    \n",
    "    acc_test  = accuracy_score(y_test,  y_pred_test_labels ) * 100\n",
    "    acc_train = accuracy_score(y_train, y_pred_train_labels) * 100\n",
    "    \n",
    "    return acc_test, CE_test, acc_train, CE_train, model.converge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name: Datasets\\aecoli.csv\n",
      "Start Normal:\n",
      "Start Platt:\n",
      "Start SKLearn:\n",
      "Start Method1:\n",
      "Start Method2:\n",
      "{'Name': 'Datasets\\\\aecoli.csv', 'Instances': 336, 'Features': 5, 'PosClassRatio': 0.4255952380952381, 'NTestCE': 0.9783244490579448, 'M1TestCE': 0.9203804579897958, 'M2TestCE': 1.1671208990533848, 'PTestCE': 0.9601715913251816, 'SKTestCE': 1.4090697931398577, 'NTrainCE': 0.1810728469896361, 'M1TrainCE': 0.18728417561358843, 'M2TrainCE': 0.15422011183586795, 'PTrainCE': 0.18515596817991994, 'SKTrainCE': 0.11386393770760568, 'NTestAcc': 54.45544554455446, 'M1TestAcc': 54.45544554455446, 'M2TestAcc': 54.45544554455446, 'PTestAcc': 54.45544554455446, 'SKTestAcc': 54.45544554455446, 'NTrainAcc': 95.74468085106383, 'M1TrainAcc': 96.17021276595744, 'M2TrainAcc': 95.31914893617022, 'PTrainAcc': 96.17021276595744, 'SKTrainAcc': 96.59574468085106, 'NConverge': 500, 'M1Converge': 500, 'M2Converge': 500, 'PConverge': 500} \n",
      "########################################\n",
      "\n",
      "Dataset Name: Datasets\\balloon.csv\n",
      "Start Normal:\n",
      "Start Platt:\n",
      "Start SKLearn:\n",
      "Start Method1:\n",
      "Start Method2:\n",
      "{'Name': 'Datasets\\\\balloon.csv', 'Instances': 2001, 'Features': 1, 'PosClassRatio': 0.24087956021989004, 'NTestCE': 1.4894910334409148, 'M1TestCE': 1.1095523405720236, 'M2TestCE': 1.4234277442645227, 'PTestCE': 1.4792632892361108, 'SKTestCE': 1.5110522708467748, 'NTrainCE': 0.35823604633562234, 'M1TrainCE': 0.4552336258233621, 'M2TrainCE': 0.35895286529401305, 'PTrainCE': 0.3582900575978042, 'SKTrainCE': 0.3581654882536409, 'NTestAcc': 72.3793677204659, 'M1TestAcc': 72.3793677204659, 'M2TestAcc': 72.3793677204659, 'PTestAcc': 72.3793677204659, 'SKTestAcc': 72.3793677204659, 'NTrainAcc': 85.42857142857143, 'M1TrainAcc': 76.07142857142857, 'M2TrainAcc': 85.42857142857143, 'PTrainAcc': 85.42857142857143, 'SKTrainAcc': 85.42857142857143, 'NConverge': 500, 'M1Converge': 500, 'M2Converge': 500, 'PConverge': 500} \n",
      "########################################\n",
      "\n",
      "Dataset Name: Datasets\\banana.csv\n",
      "Start Normal:\n",
      "Start Platt:\n",
      "Start SKLearn:\n",
      "Start Method1:\n",
      "Start Method2:\n",
      "{'Name': 'Datasets\\\\banana.csv', 'Instances': 5300, 'Features': 2, 'PosClassRatio': 0.4483018867924528, 'NTestCE': 0.6912755033639105, 'M1TestCE': 0.6896526631871233, 'M2TestCE': 0.6906142514505249, 'PTestCE': 0.6912740546423871, 'SKTestCE': 0.6912634755016047, 'NTrainCE': 0.6815724422741177, 'M1TrainCE': 0.682467880082351, 'M2TrainCE': 0.6818774279110873, 'PTrainCE': 0.6815724613223758, 'SKTrainCE': 0.6815724365931036, 'NTestAcc': 54.52830188679245, 'M1TestAcc': 49.43396226415094, 'M2TestAcc': 56.10062893081761, 'PTestAcc': 54.52830188679245, 'SKTestAcc': 54.59119496855346, 'NTrainAcc': 56.57681940700808, 'M1TrainAcc': 51.509433962264154, 'M2TrainAcc': 58.544474393531, 'PTrainAcc': 56.57681940700808, 'SKTrainAcc': 56.60377358490566, 'NConverge': 500, 'M1Converge': 500, 'M2Converge': 500, 'PConverge': 500} \n",
      "########################################\n",
      "\n",
      "Dataset Name: Datasets\\blood transfusion center.csv\n",
      "Start Normal:\n",
      "Start Platt:\n",
      "Start SKLearn:\n",
      "Start Method1:\n",
      "Start Method2:\n",
      "{'Name': 'Datasets\\\\blood transfusion center.csv', 'Instances': 748, 'Features': 4, 'PosClassRatio': 0.23796791443850268, 'NTestCE': 16.486509286560594, 'M1TestCE': 16.486509286560594, 'M2TestCE': 16.486509286560594, 'PTestCE': 16.486509286560594, 'SKTestCE': 16.486509286560594, 'NTrainCE': 0.4817330344048105, 'M1TrainCE': 0.49044627527369744, 'M2TrainCE': 0.4856002556933302, 'PTrainCE': 0.4819210521235225, 'SKTrainCE': 0.48051567844455706, 'NTestAcc': 20.444444444444446, 'M1TestAcc': 20.444444444444446, 'M2TestAcc': 20.444444444444446, 'PTestAcc': 20.444444444444446, 'SKTestAcc': 20.444444444444446, 'NTrainAcc': 76.48183556405354, 'M1TrainAcc': 77.43785850860421, 'M2TrainAcc': 76.09942638623328, 'PTrainAcc': 76.48183556405354, 'SKTrainAcc': 77.24665391969407, 'NConverge': 500, 'M1Converge': 500, 'M2Converge': 500, 'PConverge': 500} \n",
      "########################################\n",
      "\n",
      "Dataset Name: Datasets\\chscase_vine2.csv\n",
      "Start Normal:\n",
      "Start Platt:\n",
      "Start SKLearn:\n",
      "Start Method1:\n",
      "Start Method2:\n",
      "{'Name': 'Datasets\\\\chscase_vine2.csv', 'Instances': 468, 'Features': 2, 'PosClassRatio': 0.5470085470085471, 'NTestCE': 0.6939630689927679, 'M1TestCE': 0.6942187923516449, 'M2TestCE': 29.194422662571995, 'PTestCE': 0.6944032117773138, 'SKTestCE': 12.4315998497637, 'NTrainCE': 0.692962389145055, 'M1TrainCE': 0.6931024325449043, 'M2TrainCE': 0.6839624529769827, 'PTrainCE': 0.6929626009837739, 'SKTrainCE': 0.6817090759914699, 'NTestAcc': 51.77304964539007, 'M1TestAcc': 48.226950354609926, 'M2TestAcc': 51.77304964539007, 'PTestAcc': 51.77304964539007, 'SKTestAcc': 51.77304964539007, 'NTrainAcc': 57.49235474006116, 'M1TrainAcc': 57.49235474006116, 'M2TrainAcc': 57.49235474006116, 'PTrainAcc': 57.49235474006116, 'SKTrainAcc': 57.49235474006116, 'NConverge': 0, 'M1Converge': 0, 'M2Converge': 500, 'PConverge': 0} \n",
      "########################################\n",
      "\n",
      "Dataset Name: Datasets\\cleve.csv\n",
      "Start Normal:\n",
      "Start Platt:\n",
      "Start SKLearn:\n",
      "Start Method1:\n",
      "Start Method2:\n",
      "{'Name': 'Datasets\\\\cleve.csv', 'Instances': 303, 'Features': 13, 'PosClassRatio': 0.45544554455445546, 'NTestCE': 11.580899638853626, 'M1TestCE': 11.585255768603973, 'M2TestCE': 10.635635817893633, 'PTestCE': 11.340646350280824, 'SKTestCE': 9.613324398136946, 'NTrainCE': 0.38449336809607154, 'M1TrainCE': 0.38480581260565344, 'M2TrainCE': 0.4007219846497081, 'PTrainCE': 0.3862417817620432, 'SKTrainCE': 0.37371194608877695, 'NTestAcc': 61.53846153846154, 'M1TestAcc': 60.43956043956044, 'M2TestAcc': 60.43956043956044, 'PTestAcc': 61.53846153846154, 'SKTestAcc': 65.93406593406593, 'NTrainAcc': 84.43396226415094, 'M1TrainAcc': 83.49056603773585, 'M2TrainAcc': 81.60377358490565, 'PTrainAcc': 84.43396226415094, 'SKTrainAcc': 84.43396226415094, 'NConverge': 500, 'M1Converge': 500, 'M2Converge': 500, 'PConverge': 500} \n",
      "########################################\n",
      "\n",
      "Dataset Name: Datasets\\delta_ailerons.csv\n",
      "Start Normal:\n",
      "Start Platt:\n",
      "Start SKLearn:\n",
      "Start Method1:\n",
      "Start Method2:\n",
      "{'Name': 'Datasets\\\\delta_ailerons.csv', 'Instances': 7129, 'Features': 5, 'PosClassRatio': 0.5306494599523075, 'NTestCE': 0.6819170423595546, 'M1TestCE': 0.6821995453491959, 'M2TestCE': 0.6820060432895645, 'PTestCE': 0.6819446602955991, 'SKTestCE': 0.6819679848700951, 'NTrainCE': 0.19417188848871975, 'M1TrainCE': 0.19441557261011427, 'M2TrainCE': 0.1949260923143622, 'PTrainCE': 0.19418323768000642, 'SKTrainCE': 0.19417661618456805, 'NTestAcc': 53.576437587657786, 'M1TestAcc': 53.71669004207573, 'M2TestAcc': 53.52968676951847, 'PTestAcc': 53.52968676951847, 'SKTestAcc': 53.576437587657786, 'NTrainAcc': 94.04809619238476, 'M1TrainAcc': 93.96793587174349, 'M2TrainAcc': 94.0881763527054, 'PTrainAcc': 94.06813627254509, 'SKTrainAcc': 94.04809619238476, 'NConverge': 500, 'M1Converge': 500, 'M2Converge': 500, 'PConverge': 500} \n",
      "########################################\n",
      "\n",
      "Dataset Name: Datasets\\eegeyestate.csv\n",
      "Start Normal:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s-moh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\s-moh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Platt:\n",
      "Start SKLearn:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s-moh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "C:\\Users\\s-moh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Method1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s-moh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\s-moh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Method2:\n",
      "{'Name': 'Datasets\\\\eegeyestate.csv', 'Instances': 14980, 'Features': 14, 'PosClassRatio': 0.4487983978638184, 'NTestCE': 11.56776114225859, 'M1TestCE': 11.567758930711454, 'M2TestCE': 11.56776114225859, 'PTestCE': 11.56776114225859, 'SKTestCE': 11.56776114225859, 'NTrainCE': 0.6458341029950391, 'M1TrainCE': 0.6476193609024022, 'M2TrainCE': 0.649001980481579, 'PTrainCE': 0.6458342204233267, 'SKTrainCE': 0.6444785270318015, 'NTestAcc': 44.192256341789054, 'M1TestAcc': 44.192256341789054, 'M2TestAcc': 44.192256341789054, 'PTestAcc': 44.192256341789054, 'SKTestAcc': 44.192256341789054, 'NTrainAcc': 62.94106427617776, 'M1TrainAcc': 62.254434484074004, 'M2TrainAcc': 63.169940873545684, 'PTrainAcc': 62.90291817661644, 'SKTrainAcc': 63.21762349799733, 'NConverge': 500, 'M1Converge': 500, 'M2Converge': 500, 'PConverge': 500} \n",
      "########################################\n",
      "\n",
      "Dataset Name: Datasets\\fri_c0_1000_5.csv\n",
      "Start Normal:\n",
      "Start Platt:\n",
      "Start SKLearn:\n",
      "Start Method1:\n",
      "Start Method2:\n",
      "{'Name': 'Datasets\\\\fri_c0_1000_5.csv', 'Instances': 1000, 'Features': 5, 'PosClassRatio': 0.503, 'NTestCE': 0.40314842820652236, 'M1TestCE': 0.4036050862102055, 'M2TestCE': 0.40119498872050263, 'PTestCE': 0.4032077269068774, 'SKTestCE': 0.4071466887447241, 'NTrainCE': 0.3420335523291958, 'M1TrainCE': 0.3460137436730547, 'M2TrainCE': 0.3484625306947236, 'PTrainCE': 0.34269235397356923, 'SKTrainCE': 0.33672172124070104, 'NTestAcc': 83.33333333333334, 'M1TestAcc': 83.66666666666667, 'M2TestAcc': 83.66666666666667, 'PTestAcc': 83.33333333333334, 'SKTestAcc': 83.33333333333334, 'NTrainAcc': 85.57142857142857, 'M1TrainAcc': 85.71428571428571, 'M2TrainAcc': 85.57142857142857, 'PTrainAcc': 85.57142857142857, 'SKTrainAcc': 85.42857142857143, 'NConverge': 500, 'M1Converge': 500, 'M2Converge': 500, 'PConverge': 500} \n",
      "########################################\n",
      "\n",
      "Dataset Name: Datasets\\house_8L.csv\n",
      "Start Normal:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s-moh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\s-moh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Platt:\n",
      "Start SKLearn:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s-moh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "C:\\Users\\s-moh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Method1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s-moh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\s-moh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Method2:\n",
      "{'Name': 'Datasets\\\\house_8L.csv', 'Instances': 22784, 'Features': 8, 'PosClassRatio': 0.704002808988764, 'NTestCE': inf, 'M1TestCE': inf, 'M2TestCE': inf, 'PTestCE': inf, 'SKTestCE': inf, 'NTrainCE': 0.3823840584863952, 'M1TrainCE': 0.4609979205225054, 'M2TrainCE': 0.4141500298944101, 'PTrainCE': 0.3823858643746239, 'SKTrainCE': 0.3823838042872227, 'NTestAcc': 29.03744880046811, 'M1TestAcc': 29.03744880046811, 'M2TestAcc': 29.008191925102402, 'PTestAcc': 29.03744880046811, 'SKTestAcc': 29.03744880046811, 'NTrainAcc': 85.2771507399047, 'M1TrainAcc': 81.77200902934537, 'M2TrainAcc': 83.75344870830197, 'PTrainAcc': 85.29596187609731, 'SKTrainAcc': 85.2771507399047, 'NConverge': 500, 'M1Converge': 500, 'M2Converge': 500, 'PConverge': 500} \n",
      "########################################\n",
      "\n",
      "Dataset Name: Datasets\\MagicTelescope.csv\n",
      "Start Normal:\n",
      "Start Platt:\n",
      "Start SKLearn:\n",
      "Start Method1:\n",
      "Start Method2:\n",
      "{'Name': 'Datasets\\\\MagicTelescope.csv', 'Instances': 19020, 'Features': 10, 'PosClassRatio': 0.3516298633017876, 'NTestCE': 13.339674185349525, 'M1TestCE': 13.33973982137718, 'M2TestCE': 13.332091257894781, 'PTestCE': 13.339668851694176, 'SKTestCE': 13.339677574193475, 'NTrainCE': 0.4569296389307183, 'M1TrainCE': 0.5913903487654948, 'M2TrainCE': 0.46666389246962614, 'PTrainCE': 0.45692973941579457, 'SKTrainCE': 0.45692612379107816, 'NTestAcc': 35.629162285313704, 'M1TestAcc': 35.629162285313704, 'M2TestAcc': 35.629162285313704, 'PTestAcc': 35.629162285313704, 'SKTestAcc': 35.629162285313704, 'NTrainAcc': 79.16478894396876, 'M1TrainAcc': 77.35466426318162, 'M2TrainAcc': 78.42872164638726, 'PTrainAcc': 79.17229983476041, 'SKTrainAcc': 79.12723449001051, 'NConverge': 500, 'M1Converge': 500, 'M2Converge': 500, 'PConverge': 500} \n",
      "########################################\n",
      "\n",
      "Dataset Name: Datasets\\mammography.csv\n",
      "Start Normal:\n",
      "Start Platt:\n",
      "Start SKLearn:\n",
      "Start Method1:\n",
      "Start Method2:\n",
      "{'Name': 'Datasets\\\\mammography.csv', 'Instances': 11183, 'Features': 6, 'PosClassRatio': 0.023249575248144506, 'NTestCE': 0.05693663380682826, 'M1TestCE': 0.1557297913177632, 'M2TestCE': 0.057932670939714784, 'PTestCE': 0.057003839829289915, 'SKTestCE': 0.055204288880881136, 'NTrainCE': 0.058738807688867134, 'M1TrainCE': 0.1581576839609239, 'M2TrainCE': 0.059419088690942264, 'PTrainCE': 0.05877521355099819, 'SKTrainCE': 0.05752020805018637, 'NTestAcc': 98.45007451564828, 'M1TestAcc': 94.45603576751118, 'M2TestAcc': 98.12220566318926, 'PTestAcc': 98.45007451564828, 'SKTestAcc': 98.47988077496275, 'NTrainAcc': 98.27542156361778, 'M1TrainAcc': 94.76239141543178, 'M2TrainAcc': 98.26264690853347, 'PTrainAcc': 98.27542156361778, 'SKTrainAcc': 98.30097087378641, 'NConverge': 500, 'M1Converge': 500, 'M2Converge': 500, 'PConverge': 500} \n",
      "########################################\n",
      "\n",
      "Dataset Name: Datasets\\phoneme.csv\n",
      "Start Normal:\n",
      "Start Platt:\n",
      "Start SKLearn:\n",
      "Start Method1:\n",
      "Start Method2:\n",
      "{'Name': 'Datasets\\\\phoneme.csv', 'Instances': 5404, 'Features': 5, 'PosClassRatio': 0.2934863064396743, 'NTestCE': 0.48528368907450425, 'M1TestCE': 0.5539207288346337, 'M2TestCE': 0.48547807706678203, 'PTestCE': 0.48525477915673, 'SKTestCE': 0.4852538040844854, 'NTrainCE': 0.4647253829155699, 'M1TrainCE': 0.5253551814489736, 'M2TrainCE': 0.46728539042718065, 'PTrainCE': 0.46472574839519676, 'SKTrainCE': 0.4647257106674815, 'NTestAcc': 73.98273736128237, 'M1TestAcc': 74.29099876695437, 'M2TestAcc': 73.18125770653513, 'PTestAcc': 73.98273736128237, 'SKTestAcc': 73.98273736128237, 'NTrainAcc': 75.5156002115283, 'M1TrainAcc': 75.1718667371761, 'M2TrainAcc': 74.53728186144897, 'PTrainAcc': 75.5156002115283, 'SKTrainAcc': 75.48915917503966, 'NConverge': 500, 'M1Converge': 500, 'M2Converge': 500, 'PConverge': 500} \n",
      "########################################\n",
      "\n",
      "Dataset Name: Datasets\\pollen.csv\n",
      "Start Normal:\n",
      "Start Platt:\n",
      "Start SKLearn:\n",
      "Start Method1:\n",
      "Start Method2:\n",
      "{'Name': 'Datasets\\\\pollen.csv', 'Instances': 3848, 'Features': 5, 'PosClassRatio': 0.5, 'NTestCE': 0.7197931453852068, 'M1TestCE': 0.7121493463474644, 'M2TestCE': 0.7111695329932057, 'PTestCE': 0.7193998222287598, 'SKTestCE': 0.7169923468370659, 'NTrainCE': 0.6925929277335325, 'M1TrainCE': 0.6926424513017384, 'M2TrainCE': 0.6929133474332185, 'PTrainCE': 0.6925930113465436, 'SKTrainCE': 0.6925859528930145, 'NTestAcc': 49.95670995670996, 'M1TestAcc': 49.43722943722943, 'M2TestAcc': 51.082251082251084, 'PTestAcc': 50.04329004329004, 'SKTestAcc': 50.82251082251082, 'NTrainAcc': 51.46676568882287, 'M1TrainAcc': 51.02116598588934, 'M2TrainAcc': 49.23876717415522, 'PTrainAcc': 51.16969922020051, 'SKTrainAcc': 50.6869662086892, 'NConverge': 500, 'M1Converge': 500, 'M2Converge': 500, 'PConverge': 500} \n",
      "########################################\n",
      "\n",
      "Dataset Name: Datasets\\quake.csv\n",
      "Start Normal:\n",
      "Start Platt:\n",
      "Start SKLearn:\n",
      "Start Method1:\n",
      "Start Method2:\n",
      "{'Name': 'Datasets\\\\quake.csv', 'Instances': 2178, 'Features': 3, 'PosClassRatio': 0.5550964187327824, 'NTestCE': 4.891828097762438, 'M1TestCE': 5.398589251581821, 'M2TestCE': 5.457056821229267, 'PTestCE': 4.879428550031709, 'SKTestCE': 4.882269680924893, 'NTrainCE': 0.6840328823818033, 'M1TrainCE': 0.6868176422122968, 'M2TrainCE': 0.6840971583616572, 'PTrainCE': 0.6840329017369614, 'SKTrainCE': 0.6840329079925901, 'NTestAcc': 53.05810397553516, 'M1TestAcc': 53.822629969418955, 'M2TestAcc': 53.05810397553516, 'PTestAcc': 53.05810397553516, 'SKTestAcc': 53.05810397553516, 'NTrainAcc': 55.90551181102362, 'M1TrainAcc': 55.70866141732284, 'M2TrainAcc': 55.90551181102362, 'PTrainAcc': 55.90551181102362, 'SKTrainAcc': 55.90551181102362, 'NConverge': 500, 'M1Converge': 500, 'M2Converge': 500, 'PConverge': 500} \n",
      "########################################\n",
      "\n",
      "Dataset Name: Datasets\\space_ga.csv\n",
      "Start Normal:\n",
      "Start Platt:\n",
      "Start SKLearn:\n",
      "Start Method1:\n",
      "Start Method2:\n",
      "{'Name': 'Datasets\\\\space_ga.csv', 'Instances': 3107, 'Features': 6, 'PosClassRatio': 0.4959768265207596, 'NTestCE': 10.52821867743556, 'M1TestCE': 10.52821867743556, 'M2TestCE': 10.52821867743556, 'PTestCE': 10.52821867743556, 'SKTestCE': 10.52821867743556, 'NTrainCE': 0.4808241865608214, 'M1TrainCE': 0.48186240231830557, 'M2TrainCE': 0.4621461547510104, 'PTrainCE': 0.48088531943706314, 'SKTrainCE': 0.4078380822808082, 'NTestAcc': 49.19614147909968, 'M1TestAcc': 49.19614147909968, 'M2TestAcc': 49.19614147909968, 'PTestAcc': 49.19614147909968, 'SKTestAcc': 49.19614147909968, 'NTrainAcc': 78.56485740570378, 'M1TrainAcc': 78.51885924563018, 'M2TrainAcc': 81.64673413063478, 'PTrainAcc': 78.56485740570378, 'SKTrainAcc': 83.76264949402024, 'NConverge': 500, 'M1Converge': 500, 'M2Converge': 500, 'PConverge': 500} \n",
      "########################################\n",
      "\n",
      "Dataset Name: Datasets\\stock.csv\n",
      "Start Normal:\n",
      "Start Platt:\n",
      "Start SKLearn:\n",
      "Start Method1:\n",
      "Start Method2:\n",
      "{'Name': 'Datasets\\\\stock.csv', 'Instances': 950, 'Features': 9, 'PosClassRatio': 0.5136842105263157, 'NTestCE': 53.96275670129891, 'M1TestCE': 52.29683752423317, 'M2TestCE': 57.196024471289036, 'PTestCE': 53.4258223889863, 'SKTestCE': 78.59788979250156, 'NTrainCE': 0.3447364240315229, 'M1TrainCE': 0.34529442662718746, 'M2TrainCE': 0.3515544217094252, 'PTrainCE': 0.3454956211037701, 'SKTrainCE': 0.316459335356054, 'NTestAcc': 46.666666666666664, 'M1TestAcc': 46.666666666666664, 'M2TestAcc': 46.666666666666664, 'PTestAcc': 46.666666666666664, 'SKTestAcc': 46.666666666666664, 'NTrainAcc': 79.09774436090225, 'M1TrainAcc': 79.69924812030075, 'M2TrainAcc': 79.3984962406015, 'PTrainAcc': 79.09774436090225, 'SKTrainAcc': 84.66165413533835, 'NConverge': 500, 'M1Converge': 500, 'M2Converge': 500, 'PConverge': 500} \n",
      "########################################\n",
      "\n",
      "Dataset Name: Datasets\\titanic.csv\n",
      "Start Normal:\n",
      "Start Platt:\n",
      "Start SKLearn:\n",
      "Start Method1:\n",
      "Start Method2:\n",
      "{'Name': 'Datasets\\\\titanic.csv', 'Instances': 2201, 'Features': 3, 'PosClassRatio': 0.3230349840981372, 'NTestCE': 0.5476459636517235, 'M1TestCE': 0.571091499612022, 'M2TestCE': 0.5433644610940105, 'PTestCE': 0.5474682248201057, 'SKTestCE': 0.5474958716395967, 'NTrainCE': 0.5124919222010398, 'M1TrainCE': 0.543533423530972, 'M2TrainCE': 0.514720007933094, 'PTrainCE': 0.5124934019800754, 'SKTrainCE': 0.5124929346295407, 'NTestAcc': 75.642965204236, 'M1TestAcc': 74.28139183055976, 'M2TestAcc': 75.642965204236, 'PTestAcc': 75.642965204236, 'SKTestAcc': 75.642965204236, 'NTrainAcc': 78.44155844155844, 'M1TrainAcc': 77.92207792207793, 'M2TrainAcc': 78.44155844155844, 'PTrainAcc': 78.44155844155844, 'SKTrainAcc': 78.44155844155844, 'NConverge': 500, 'M1Converge': 500, 'M2Converge': 500, 'PConverge': 500} \n",
      "########################################\n",
      "\n",
      "Dataset Name: Datasets\\visualizing_galaxy.csv\n",
      "Start Normal:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Platt:\n",
      "Start SKLearn:\n",
      "Start Method1:\n",
      "Start Method2:\n",
      "{'Name': 'Datasets\\\\visualizing_galaxy.csv', 'Instances': 323, 'Features': 4, 'PosClassRatio': 0.541795665634675, 'NTestCE': 0.6741489110858303, 'M1TestCE': 0.9209374580551051, 'M2TestCE': 0.7954474192154593, 'PTestCE': 0.6617848446062807, 'SKTestCE': 0.44747251136396327, 'NTrainCE': 0.2974157381219094, 'M1TrainCE': 0.30615493719078335, 'M2TrainCE': 0.27189688367804854, 'PTrainCE': 0.3019108819137248, 'SKTrainCE': 0.16371367112357893, 'NTestAcc': 89.69072164948454, 'M1TestAcc': 88.65979381443299, 'M2TestAcc': 90.72164948453609, 'PTestAcc': 89.69072164948454, 'SKTestAcc': 94.84536082474226, 'NTrainAcc': 95.57522123893806, 'M1TrainAcc': 94.69026548672566, 'M2TrainAcc': 93.80530973451327, 'PTrainAcc': 95.57522123893806, 'SKTrainAcc': 96.01769911504425, 'NConverge': 500, 'M1Converge': 500, 'M2Converge': 500, 'PConverge': 500} \n",
      "########################################\n",
      "\n",
      "Dataset Name: Datasets\\vowel.csv\n",
      "Start Normal:\n",
      "Start Platt:\n",
      "Start SKLearn:\n",
      "Start Method1:\n",
      "Start Method2:\n",
      "{'Name': 'Datasets\\\\vowel.csv', 'Instances': 990, 'Features': 10, 'PosClassRatio': 0.09090909090909091, 'NTestCE': 0.1807798582944294, 'M1TestCE': 0.17722968952442011, 'M2TestCE': 0.19422458896281056, 'PTestCE': 0.18153130866104658, 'SKTestCE': 0.32216273787463634, 'NTrainCE': 0.12900296830365635, 'M1TrainCE': 0.12928595304532817, 'M2TrainCE': 0.11416179355082817, 'PTrainCE': 0.13014020943180146, 'SKTrainCE': 0.06861403647918644, 'NTestAcc': 91.91919191919192, 'M1TestAcc': 91.91919191919192, 'M2TestAcc': 91.24579124579124, 'PTestAcc': 91.58249158249158, 'SKTestAcc': 91.58249158249158, 'NTrainAcc': 96.53679653679653, 'M1TrainAcc': 96.53679653679653, 'M2TrainAcc': 96.1038961038961, 'PTrainAcc': 96.24819624819625, 'SKTrainAcc': 97.25829725829726, 'NConverge': 500, 'M1Converge': 500, 'M2Converge': 500, 'PConverge': 500} \n",
      "########################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for f in files:\n",
    "    # Read Dataset\n",
    "    print('Dataset Name:', f)\n",
    "    data = pd.read_csv(f)\n",
    "    rows, cols, ratio = meta_features(data)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.drop('class', axis=1), data['class'], \n",
    "                                                        test_size=0.3, random_state=24)\n",
    "    X_train = (X_train - X_train.mean()) / X_train.std()\n",
    "    X_test = (X_test - X_train.mean()) / X_train.std()\n",
    "    res['Name'] = f; res['Instances'] = rows; res['Features'] = cols; res['PosClassRatio'] = ratio;\n",
    "   \n",
    "    #Normal LR\n",
    "    print('Start Normal:')\n",
    "    ac1, ce1, ac2, ce2, converge, model = normal_results(X_train, y_train, X_test, y_test)\n",
    "    res['NTestCE'] = ce1; res['NTestAcc'] = ac1; res['NTrainCE'] = ce2; res['NTrainAcc'] = ac2; res['NConverge'] = converge\n",
    "    \n",
    "    #Platt LR\n",
    "    print('Start Platt:')\n",
    "    ac1, ce1, ac2, ce2, converge = platt_results(X_train, y_train, X_test, y_test)\n",
    "    res['PTestCE'] = ce1; res['PTestAcc'] = ac1; res['PTrainCE'] = ce2; res['PTrainAcc'] = ac2; res['PConverge'] = converge\n",
    "    \n",
    "    #Sklearn Results\n",
    "    print('Start SKLearn:')\n",
    "    ac1, ce1, ac2, ce2 = sklearn_results(X_train, y_train, X_test, y_test, model)\n",
    "    res['SKTestCE'] = ce1; res['SKTestAcc'] = ac1; res['SKTrainCE'] = ce2; res['SKTrainAcc'] = ac2;\n",
    "     \n",
    "    #KDE Kernels\n",
    "    pos_kernel, neg_kernel, y_train_prob = kernels(X_train, y_train)\n",
    "    #Method 1\n",
    "    print('Start Method1:')\n",
    "    ac1, ce1, ac2, ce2, converge = M1_results(X_train, y_train, X_test, y_test, y_train_prob)\n",
    "    res['M1TestCE'] = ce1; res['M1TestAcc'] = ac1; res['M1TrainCE'] = ce2; res['M1TrainAcc'] = ac2; res['M1Converge'] = converge\n",
    "    #Method 2\n",
    "    print('Start Method2:')\n",
    "    ac1, ce1, ac2, ce2, converge = M2_results(X_train, y_train, X_test, y_test, pos_kernel, neg_kernel)\n",
    "    res['M2TestCE'] = ce1; res['M2TestAcc'] = ac1; res['M2TrainCE'] = ce2; res['M2TrainAcc'] = ac2; res['M2Converge'] = converge\n",
    "    \n",
    "    results = results.append(res, ignore_index=True)\n",
    "    print(res, '\\n########################################\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Instances</th>\n",
       "      <th>Features</th>\n",
       "      <th>PosClassRatio</th>\n",
       "      <th>NTestCE</th>\n",
       "      <th>M1TestCE</th>\n",
       "      <th>M2TestCE</th>\n",
       "      <th>PTestCE</th>\n",
       "      <th>SKTestCE</th>\n",
       "      <th>NTrainCE</th>\n",
       "      <th>...</th>\n",
       "      <th>SKTestAcc</th>\n",
       "      <th>NTrainAcc</th>\n",
       "      <th>M1TrainAcc</th>\n",
       "      <th>M2TrainAcc</th>\n",
       "      <th>PTrainAcc</th>\n",
       "      <th>SKTrainAcc</th>\n",
       "      <th>NConverge</th>\n",
       "      <th>M1Converge</th>\n",
       "      <th>M2Converge</th>\n",
       "      <th>PConverge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Datasets\\aecoli.csv</td>\n",
       "      <td>336.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.425595</td>\n",
       "      <td>0.978324</td>\n",
       "      <td>0.920380</td>\n",
       "      <td>1.167121</td>\n",
       "      <td>0.960172</td>\n",
       "      <td>1.409070</td>\n",
       "      <td>0.181073</td>\n",
       "      <td>...</td>\n",
       "      <td>54.455446</td>\n",
       "      <td>95.744681</td>\n",
       "      <td>96.170213</td>\n",
       "      <td>95.319149</td>\n",
       "      <td>96.170213</td>\n",
       "      <td>96.595745</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Datasets\\balloon.csv</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.240880</td>\n",
       "      <td>1.489491</td>\n",
       "      <td>1.109552</td>\n",
       "      <td>1.423428</td>\n",
       "      <td>1.479263</td>\n",
       "      <td>1.511052</td>\n",
       "      <td>0.358236</td>\n",
       "      <td>...</td>\n",
       "      <td>72.379368</td>\n",
       "      <td>85.428571</td>\n",
       "      <td>76.071429</td>\n",
       "      <td>85.428571</td>\n",
       "      <td>85.428571</td>\n",
       "      <td>85.428571</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Datasets\\banana.csv</td>\n",
       "      <td>5300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.448302</td>\n",
       "      <td>0.691276</td>\n",
       "      <td>0.689653</td>\n",
       "      <td>0.690614</td>\n",
       "      <td>0.691274</td>\n",
       "      <td>0.691263</td>\n",
       "      <td>0.681572</td>\n",
       "      <td>...</td>\n",
       "      <td>54.591195</td>\n",
       "      <td>56.576819</td>\n",
       "      <td>51.509434</td>\n",
       "      <td>58.544474</td>\n",
       "      <td>56.576819</td>\n",
       "      <td>56.603774</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Datasets\\blood transfusion center.csv</td>\n",
       "      <td>748.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.237968</td>\n",
       "      <td>16.486509</td>\n",
       "      <td>16.486509</td>\n",
       "      <td>16.486509</td>\n",
       "      <td>16.486509</td>\n",
       "      <td>16.486509</td>\n",
       "      <td>0.481733</td>\n",
       "      <td>...</td>\n",
       "      <td>20.444444</td>\n",
       "      <td>76.481836</td>\n",
       "      <td>77.437859</td>\n",
       "      <td>76.099426</td>\n",
       "      <td>76.481836</td>\n",
       "      <td>77.246654</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Datasets\\chscase_vine2.csv</td>\n",
       "      <td>468.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.547009</td>\n",
       "      <td>0.693963</td>\n",
       "      <td>0.694219</td>\n",
       "      <td>29.194423</td>\n",
       "      <td>0.694403</td>\n",
       "      <td>12.431600</td>\n",
       "      <td>0.692962</td>\n",
       "      <td>...</td>\n",
       "      <td>51.773050</td>\n",
       "      <td>57.492355</td>\n",
       "      <td>57.492355</td>\n",
       "      <td>57.492355</td>\n",
       "      <td>57.492355</td>\n",
       "      <td>57.492355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Name  Instances  Features  PosClassRatio  \\\n",
       "0                    Datasets\\aecoli.csv      336.0       5.0       0.425595   \n",
       "1                   Datasets\\balloon.csv     2001.0       1.0       0.240880   \n",
       "2                    Datasets\\banana.csv     5300.0       2.0       0.448302   \n",
       "3  Datasets\\blood transfusion center.csv      748.0       4.0       0.237968   \n",
       "4             Datasets\\chscase_vine2.csv      468.0       2.0       0.547009   \n",
       "\n",
       "     NTestCE   M1TestCE   M2TestCE    PTestCE   SKTestCE  NTrainCE  ...  \\\n",
       "0   0.978324   0.920380   1.167121   0.960172   1.409070  0.181073  ...   \n",
       "1   1.489491   1.109552   1.423428   1.479263   1.511052  0.358236  ...   \n",
       "2   0.691276   0.689653   0.690614   0.691274   0.691263  0.681572  ...   \n",
       "3  16.486509  16.486509  16.486509  16.486509  16.486509  0.481733  ...   \n",
       "4   0.693963   0.694219  29.194423   0.694403  12.431600  0.692962  ...   \n",
       "\n",
       "   SKTestAcc  NTrainAcc  M1TrainAcc  M2TrainAcc  PTrainAcc  SKTrainAcc  \\\n",
       "0  54.455446  95.744681   96.170213   95.319149  96.170213   96.595745   \n",
       "1  72.379368  85.428571   76.071429   85.428571  85.428571   85.428571   \n",
       "2  54.591195  56.576819   51.509434   58.544474  56.576819   56.603774   \n",
       "3  20.444444  76.481836   77.437859   76.099426  76.481836   77.246654   \n",
       "4  51.773050  57.492355   57.492355   57.492355  57.492355   57.492355   \n",
       "\n",
       "   NConverge  M1Converge  M2Converge  PConverge  \n",
       "0      500.0       500.0       500.0      500.0  \n",
       "1      500.0       500.0       500.0      500.0  \n",
       "2      500.0       500.0       500.0      500.0  \n",
       "3      500.0       500.0       500.0      500.0  \n",
       "4        0.0         0.0       500.0        0.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('Evaluation.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
